<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Exam-Ready Notes</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 40px 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .header .emoji {
            font-size: 3em;
            margin-bottom: 10px;
        }

        .content {
            padding: 40px;
        }

        .section {
            margin-bottom: 40px;
            padding: 25px;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            border-radius: 15px;
            border-left: 5px solid #667eea;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .section:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.3);
        }

        .section h2 {
            color: #667eea;
            font-size: 1.8em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #667eea;
        }

        .section h3 {
            color: #764ba2;
            font-size: 1.3em;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .section p {
            line-height: 1.8;
            color: #333;
            margin-bottom: 15px;
        }

        .section ul {
            list-style: none;
            padding-left: 0;
        }

        .section ul li {
            padding: 8px 0 8px 30px;
            position: relative;
            color: #444;
            line-height: 1.6;
        }

        .section ul li:before {
            content: "‚ñ∏";
            position: absolute;
            left: 10px;
            color: #667eea;
            font-weight: bold;
        }

        .star {
            color: #ffd700;
            font-size: 1.2em;
            margin-left: 5px;
        }

        .highlight {
            background: linear-gradient(120deg, #ffd89b 0%, #19547b 100%);
            background-clip: text;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: bold;
        }

        .important-badge {
            display: inline-block;
            background: #ff6b6b;
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 0.8em;
            margin-left: 10px;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
            }
            50% {
                transform: scale(1.05);
            }
        }

        .footer {
            background: #2d3748;
            color: white;
            text-align: center;
            padding: 20px;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8em;
            }

            .content {
                padding: 20px;
            }

            .section {
                padding: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="emoji">üìó</div>
            <h1>LARGE LANGUAGE MODELS (LLMs)</h1>
            <p>EXAM-READY NOTES</p>
        </div>

        <div class="content">
            <div class="section">
                <h2>1. What are LLMs?</h2>
                <p>LLMs are <span class="highlight">large neural networks</span> trained on massive text data to <span class="highlight">predict next tokens</span>.</p>
                
                <h3>Characteristics</h3>
                <ul>
                    <li>Billions of parameters</li>
                    <li>Emergent abilities</li>
                    <li>Few-shot learning</li>
                    <li>Task generalization</li>
                </ul>

                <h3>Examples</h3>
                <ul>
                    <li>GPT series</li>
                    <li>LLaMA</li>
                    <li>PaLM</li>
                    <li>Claude</li>
                </ul>
            </div>

            <div class="section">
                <h2>2. LLM Architecture (Deep Dive)</h2>
                
                <h3>Transformer Components</h3>
                <ul>
                    <li>Self-attention</li>
                    <li>Multi-head attention</li>
                    <li>Feed-forward layers</li>
                    <li>Positional encoding</li>
                </ul>

                <h3>Architectures</h3>
                <ul>
                    <li><span class="highlight">Decoder-only</span> -- GPT (chat, generation)</li>
                    <li><span class="highlight">Encoder--Decoder</span> -- T5 (translation)</li>
                </ul>

                <h3>Advanced Innovations <span class="star">‚≠ê</span></h3>
                <ul>
                    <li>RoPE embeddings</li>
                    <li>Sparse attention</li>
                    <li>Mixture of Experts (MoE)</li>
                    <li>Grouped Query Attention (GQA)</li>
                </ul>
            </div>

            <div class="section">
                <h2>3. Pre-training of LLMs</h2>
                
                <h3>Objectives</h3>
                <ul>
                    <li>Causal Language Modeling (CLM)</li>
                    <li>Masked Language Modeling (MLM)</li>
                    <li>Prefix LM</li>
                </ul>

                <h3>Training Data</h3>
                <ul>
                    <li>Web data</li>
                    <li>Books</li>
                    <li>Code repositories</li>
                </ul>

                <h3>Infrastructure</h3>
                <ul>
                    <li>Distributed training</li>
                    <li>GPUs / TPUs</li>
                    <li>Mixed precision (FP16/BF16)</li>
                </ul>
            </div>

            <div class="section">
                <h2>4. Fine-Tuning Techniques <span class="star">‚≠ê</span><span class="important-badge">Very Important</span></h2>
                
                <h3>Types</h3>
                <ul>
                    <li>Full fine-tuning</li>
                    <li>LoRA</li>
                    <li>QLoRA</li>
                    <li>Prefix tuning</li>
                    <li>Adapter layers</li>
                </ul>

                <h3>Instruction Tuning</h3>
                <ul>
                    <li>Trains models to follow instructions</li>
                    <li>Examples: FLAN, Alpaca</li>
                </ul>

                <h3>RLHF</h3>
                <ul>
                    <li>Human feedback</li>
                    <li>Reward modeling</li>
                    <li>PPO optimization</li>
                </ul>
            </div>

            <div class="section">
                <h2>5. Optimization & Efficiency</h2>
                
                <h3>Model Compression</h3>
                <ul>
                    <li>Quantization</li>
                    <li>Pruning</li>
                    <li>Distillation</li>
                </ul>

                <h3>Inference Optimization</h3>
                <ul>
                    <li>KV caching</li>
                    <li>Flash Attention</li>
                    <li>Speculative decoding</li>
                </ul>

                <h3>Serving Frameworks</h3>
                <ul>
                    <li>vLLM</li>
                    <li>TensorRT-LLM</li>
                    <li>llama.cpp</li>
                </ul>
            </div>

            <div class="section">
                <h2>6. Advanced Prompting (LLM-Centric)</h2>
                <ul>
                    <li>Chain-of-Thought</li>
                    <li>Self-consistency</li>
                    <li>ReAct</li>
                    <li>Tree of Thoughts</li>
                    <li>Program-Aided Language Models (PAL)</li>
                </ul>
            </div>

            <div class="section">
                <h2>7. Evaluation & Benchmarks</h2>
                
                <h3>Standard Benchmarks</h3>
                <ul>
                    <li>MMLU</li>
                    <li>GSM8K</li>
                    <li>HumanEval</li>
                    <li>TruthfulQA</li>
                    <li>HellaSwag</li>
                </ul>

                <h3>Safety Evaluation</h3>
                <ul>
                    <li>Toxicity</li>
                    <li>Bias testing</li>
                    <li>Jailbreak resistance</li>
                </ul>
            </div>

            <div class="section">
                <h2>8. LLM Applications</h2>
                <ul>
                    <li>Chatbots</li>
                    <li>Code generation</li>
                    <li>Document summarization</li>
                    <li>Enterprise assistants</li>
                </ul>

                <h3>Domain-Specific LLMs</h3>
                <ul>
                    <li>Medical</li>
                    <li>Legal</li>
                    <li>Financial</li>
                    <li>Code-focused models</li>
                </ul>
            </div>

            <div class="section">
                <h2>9. LLM Safety & Governance</h2>
                <ul>
                    <li>Hallucinations</li>
                    <li>Privacy risks</li>
                    <li>Misuse prevention</li>
                    <li>Constitutional AI</li>
                </ul>
            </div>
        </div>

        <div class="footer">
            <p>üìö Good luck with your exam! Study hard and stay focused! üí™</p>
        </div>
    </div>
</body>
</html>